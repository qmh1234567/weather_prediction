{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date       pressure     wind_speed    temperature  \\\n",
      "count  1.026550e+05  102164.000000  102642.000000  102372.000000   \n",
      "mean   2.015097e+07     987.637546       3.830137      16.581338   \n",
      "std    1.415813e+04      27.775018       1.708854       9.182736   \n",
      "min    2.013010e+07       0.000000       0.000000     -19.000000   \n",
      "25%    2.014041e+07     969.200000       2.600000       9.600000   \n",
      "50%    2.015072e+07     987.500000       3.500000      17.630000   \n",
      "75%    2.016101e+07    1010.000000       4.700000      23.900000   \n",
      "max    2.017123e+07    1041.300000      17.800000      36.500000   \n",
      "\n",
      "            humidity        rain20        rain08         cloud     visibility  \\\n",
      "count  102365.000000  98670.000000  98402.000000  40687.000000  100130.000000   \n",
      "mean       71.050372      3.083463      3.086780     68.469074    5937.232767   \n",
      "std        17.914230     10.050933      9.846583     34.377992    6741.637922   \n",
      "min         0.000000      0.000000      0.000000      0.000000       0.000000   \n",
      "25%        62.000000      0.000000      0.000000     40.000000    1500.000000   \n",
      "50%        74.500000      0.000000      0.000000     80.000000    3401.000000   \n",
      "75%        84.000000      0.900000      1.100000    100.000000    8000.000000   \n",
      "max       100.000000    268.399900    258.899900    103.330000   50000.000000   \n",
      "\n",
      "               sunny  ...        thunder      lightning           snow  \\\n",
      "count  102655.000000  ...  102655.000000  102655.000000  102655.000000   \n",
      "mean        0.244956  ...       0.010384       0.011047       0.014865   \n",
      "std         0.430063  ...       0.101373       0.104522       0.121014   \n",
      "min         0.000000  ...       0.000000       0.000000       0.000000   \n",
      "25%         0.000000  ...       0.000000       0.000000       0.000000   \n",
      "50%         0.000000  ...       0.000000       0.000000       0.000000   \n",
      "75%         0.000000  ...       0.000000       0.000000       0.000000   \n",
      "max         1.000000  ...       1.000000       1.000000       1.000000   \n",
      "\n",
      "                hail           wind           year          month  \\\n",
      "count  102655.000000  102655.000000  102655.000000  102655.000000   \n",
      "mean        0.002445       0.010569    2015.030442       6.535765   \n",
      "std         0.049388       0.102263       1.415439       3.450631   \n",
      "min         0.000000       0.000000    2013.000000       1.000000   \n",
      "25%         0.000000       0.000000    2014.000000       4.000000   \n",
      "50%         0.000000       0.000000    2015.000000       7.000000   \n",
      "75%         0.000000       0.000000    2016.000000      10.000000   \n",
      "max         1.000000       1.000000    2017.000000      12.000000   \n",
      "\n",
      "                week        quarter            day  \n",
      "count  102655.000000  102653.000000  102655.000000  \n",
      "mean       26.670342       2.512347     183.479821  \n",
      "std        15.070427       1.117836     105.471395  \n",
      "min         1.000000       1.000000       1.000000  \n",
      "25%        14.000000       2.000000      92.000000  \n",
      "50%        27.000000       3.000000     184.000000  \n",
      "75%        40.000000       4.000000     275.000000  \n",
      "max        53.000000       4.000000     365.000000  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('./datasets/clean_weather.csv')\n",
    "print(weather.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date station city county  pressure  wind_speed  wind_direction  \\\n",
      "0  20130101      巴南  重庆市    巴南市     959.1         3.4          999003   \n",
      "1  20130101      綦江  重庆市    綦江市     962.6         6.5          999012   \n",
      "2  20130101      渝北  重庆市    渝北市     963.9         4.1          999003   \n",
      "3  20130101      梁平  重庆市    梁平市     965.3         2.2          999001   \n",
      "4  20130101      垫江  重庆市    垫江县     968.9         1.7          999004   \n",
      "\n",
      "   temperature  humidity  rain20  ...  cloudy  rain  fog haze  dust  thunder  \\\n",
      "0          6.0      48.0     0.0  ...       1     0    0    0     0        0   \n",
      "1          5.6      59.0     0.0  ...       0     0    0    0     0        0   \n",
      "2          5.9      44.0     0.0  ...       1     0    0    0     0        0   \n",
      "3          2.1      68.0     0.0  ...       1     0    1    0     0        0   \n",
      "4          3.8      61.0     0.0  ...       1     0    0    0     0        0   \n",
      "\n",
      "   lightning  snow  hail  wind  \n",
      "0          0     0     0     0  \n",
      "1          0     0     0     0  \n",
      "2          0     0     0     0  \n",
      "3          0     0     0     0  \n",
      "4          0     0     0     0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(weather['date'].value_counts())\n",
    "# print(weather.groupby(weather['date']))\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def gen_dates(b_date,days):\n",
    "    day = timedelta(days=1)\n",
    "    for i in range(days):\n",
    "        yield b_date+ day*i\n",
    "\n",
    "def get_date_list(start_date,end_date):\n",
    "    start = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.datetime.strptime(end_date,\"%Y-%m-%d\")\n",
    "    data = []\n",
    "    for d in gen_dates(start,((end-start).days+1)):\n",
    "        data.append(d.strftime(\"%Y-%-m-%-d\"))\n",
    "    return data\n",
    "\n",
    "\n",
    "def covert_txt_to_dataframe(txt_path,date_list):\n",
    "    # 将txt转成dataframe\n",
    "    with open(txt_path,'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        df_dict = {\n",
    "            'date':[],\n",
    "            'AQI':[],\n",
    "            'Quality_rank':[],\n",
    "        }\n",
    "\n",
    "        for i,start in enumerate(range(8,len(lines)-1,3)):\n",
    "            try:\n",
    "                index = len(date_list[i])\n",
    "                day = lines[start][:index]\n",
    "                df_dict['date'].append(day)\n",
    "                df_dict['AQI'].append(lines[start][index:])\n",
    "                df_dict['Quality_rank'].append(lines[start+1])\n",
    "            except Exception as e:\n",
    "                print(lines[start])\n",
    "                print(e)\n",
    "    return df_dict\n",
    "\n",
    "# 北京市\n",
    "def beijing_convert():\n",
    "    # 得到时间列表\n",
    "    date_list = get_date_list('2013-12-2','2017-12-6')\n",
    "    date_list.pop(date_list.index('2016-4-16'))\n",
    "    print(len(date_list))\n",
    "    df_dict = covert_txt_to_dataframe('./datasets/beijing_air.txt',date_list)\n",
    "    bj_df = pd.DataFrame(df_dict)\n",
    "    date = pd.to_datetime(df['date'].apply(lambda x: str(x)))\n",
    "    bj_df['date'] = date\n",
    "    print(bj_df.info())\n",
    "    return bj_df\n",
    "    \n",
    "# 重庆市\n",
    "def chongqin_convert():\n",
    "    # 得到时间列表\n",
    "    date_list = get_date_list('2013-12-2','2017-12-16')\n",
    "    print(len(date_list))\n",
    "    cq_dict = covert_txt_to_dataframe('./datasets/chongqing_air.txt',date_list)\n",
    "    cq_df = pd.DataFrame(cq_dict)\n",
    "    date = pd.to_datetime(cq_df['date'].apply(lambda x: str(x)))\n",
    "    cq_df['date'] = date\n",
    "    print(cq_df.info())\n",
    "    return cq_df\n",
    "\n",
    "# 上海市\n",
    "def shanghai_convert():\n",
    "     # 得到时间列表\n",
    "    date_list = get_date_list('2013-12-2','2017-12-6')\n",
    "    print(len(date_list))\n",
    "    sh_dict = covert_txt_to_dataframe('./datasets/shanghai_air.txt',date_list)\n",
    "    sh_df = pd.DataFrame(sh_dict)\n",
    "    date = pd.to_datetime(sh_df['date'].apply(lambda x: str(x)))\n",
    "    sh_df['date'] = date\n",
    "    print(sh_df.info())\n",
    "    return sh_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./group_weather.csv' does not exist: b'./group_weather.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-1630b5fa6194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/group_weather.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew_weather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./group_weather.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnew_weather\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_weather\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./group_weather.csv' does not exist: b'./group_weather.csv'"
     ]
    }
   ],
   "source": [
    "# grouped = weather.groupby(['city','date'])\n",
    "df_group = weather.groupby([weather['city'],weather['date']]).mean()\n",
    "df_group.to_csv('./datasets/group_weather.csv',index=False)\n",
    "new_weather = pd.read_csv('./datasets/group_weather.csv')\n",
    "new_weather['date'] = pd.to_datetime(new_weather['date'].apply(lambda x: str(x)))\n",
    "\n",
    "bj_df = beijing_convert()\n",
    "beijing = new_weather.loc[new_weather['city']=='北京市']\n",
    "new_beijing = pd.merge(bj_df,beijing,how=\"inner\",on='date') \n",
    "\n",
    "cq_df = chongqin_convert()\n",
    "chongqin = new_weather.loc[new_weather['city']=='重庆市']\n",
    "new_chongqing = pd.merge(cq_df,chongqin,how='inner',on='date')\n",
    "\n",
    "sh_df = shanghai_convert()\n",
    "shanghai = new_weather.loc[new_weather['city']=='上海市']\n",
    "new_shanghai = pd.merge(sh_df,shanghai,how='inner',on='date')\n",
    "\n",
    "new_weather1 = pd.concat([new_beijing,new_chongqing,new_shanghai])\n",
    "new_weather1.to_csv('./datasets/air_weather.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
